# ä½¿ç”¨ HuggingFace å’Œ Elasticsearch è¿›è¡Œè¯­ä¹‰æœç´¢

> åŸæ–‡ï¼š<https://betterprogramming.pub/implementing-nearest-neighbour-search-with-elasticsearch-c59a8d33dd9d>

## è®©æˆ‘ä»¬ä½¿ç”¨æœ€è¿‘é‚»æœç´¢å¯¹æ•°æ®é›†ä¸­çš„æ®µè½è¿›è¡Œæ’åº

![](img/ca7af4cf21f724eb1f4d4789fe730836.png)

é©¬åº“æ–¯Â·æ¸©å…‹å‹’åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

å¯†é›†åµŒå…¥æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„æ¸¸æˆæ”¹å˜è€…ï¼Œå°¤å…¶æ˜¯åœ¨æœç´¢å¼•æ“å’Œæ¨èç³»ç»Ÿä¸­ã€‚å¯†é›†åµŒå…¥ç›®å‰è¢«åº”ç”¨äºè‡ªç»„ç»‡ä¿¡æ¯æ£€ç´¢ã€äº§å“æœç´¢ã€æ¨èå¼•æ“ç­‰ã€‚è®¸å¤šå…¬å¸ç›®å‰æ­£åœ¨ä»–ä»¬çš„å·¥ä½œæµç¨‹ä¸­é‡‡ç”¨æŸç§å½¢å¼çš„åŸºäºåµŒå…¥çš„æœç´¢ã€‚

ä¸€äº›å…³äºå½“å‰é¡¶çº§å…¬å¸å¦‚ä½•é›†æˆå¯†é›†åµŒå…¥çš„æ–‡ç« æœ‰ [Instacart](https://sigir-ecom.github.io/ecom22Papers/paper_8392.pdf) ã€ [DoorDash](https://doordash.news/company/powering-search-recommendations-at-doordash/) ã€ [Etsy](https://www.etsy.com/codeascraft/deep-learning-for-search-ranking-at-etsy?utm_source=pocket_reader) ã€ [Google](https://blog.google/products/search/search-language-understanding-bert/) å’Œ [Airbnb](https://medium.com/airbnb-engineering/improving-deep-learning-for-ranking-stays-at-airbnb-959097638bde) ã€‚

Google çš„ Talk to books å¾ˆå¥½åœ°æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¯†é›†å‘é‡è¿›è¡Œæœç´¢ã€‚è¿™ç§å½¢å¼çš„æœç´¢é€šå¸¸è¢«ç§°ä¸ºè¯­ä¹‰æœç´¢ã€‚è¯¥æ¼”ç¤ºä½¿ç”¨ç¼–ç å™¨æ¨¡å‹ä»å­˜å‚¨åœ¨ç´¢å¼•ä¸­çš„æ–‡æ¡£(åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æ˜¯ä¹¦ç±)ç”ŸæˆåµŒå…¥ï¼Œå¹¶åœ¨æœç´¢æ—¶ä¸æŸ¥è¯¢å‘é‡è¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ£€ç´¢ä¸ç»™å®šæŸ¥è¯¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£ã€‚è¯­ä¹‰æœç´¢æ˜¯å¯¹ BM25 ç­‰ä¼ ç»Ÿå…³é”®è¯æœç´¢ç®—æ³•çš„é‡å¤§å‡çº§ï¼Œå› ä¸ºå®ƒå¯ä»¥æ£€ç´¢ä¸ç»™å®šæŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£ï¼Œä½†ä¸ä¸€å®šåŒ…å«ä¸æŸ¥è¯¢å®Œå…¨ç›¸åŒçš„å•è¯ã€‚

> **è¾¹æ³¨**:æ¼”ç¤ºä¸­ä½¿ç”¨çš„è¿™ä¸ªæ¨¡å‹([é€šç”¨è¯­å¥ç¼–ç å™¨](https://arxiv.org/abs/1803.11175)))åœ¨æ·±åº¦å­¦ä¹ è°±ç³»ä¸­æœ‰äº›é™ˆæ—§ï¼Œæœ‰ä¸€äº›æ¨¡å‹å¯ä»¥äº§ç”Ÿæ›´å¥½çš„åµŒå…¥ï¼Œå…¶ä¸­ä¸€äº›å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°[ã€‚](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads)

# ä»€ä¹ˆæ˜¯å¯†é›†åµŒå…¥ï¼Ÿ

![](img/edae136fdba96dbdd3ddac515897fa77.png)

å¯†é›†åµŒå…¥æ˜¯æ•°æ®(æ–‡æœ¬ã€ç”¨æˆ·ã€äº§å“ç­‰)çš„æ•°å­—è¡¨ç¤ºã€‚)ä½¿ç”¨é«˜ç»´å‘é‡ã€‚å¯†é›†å‘é‡å…·æœ‰ä¸åŒçš„é•¿åº¦ï¼Œå¹¶è¢«æœŸæœ›å¯¹å…³äºåŸå§‹æ•°æ®çš„ä¿¡æ¯è¿›è¡Œç¼–ç ï¼Œä»¥ä¾¿ä½¿ç”¨åƒ[ä½™å¼¦ç›¸ä¼¼åº¦](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)è¿™æ ·çš„å‘é‡ç›¸ä¼¼åº¦ç®—æ³•æ¥å®¹æ˜“åœ°æ‰¾åˆ°ç›¸ä¼¼çš„æ•°æ®ç‚¹ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„å®ç°:

```
from sklearn.metrics.pairwise import cosine_similarity
from numpy import random

array_vec_1 = random.rand(1,10)
array_vec_2 = random.rand(1,10)
print(cosine_similarity(array_vec_1, array_vec_2))
```

> **è¾¹æ³¨**:ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œè¶Šç›¸ä¼¼ã€‚ä½™å¼¦ç›¸ä¼¼æ€§ä¹Ÿè¢«ç”¨ä½œè®­ç»ƒç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ã€‚å‚è§ py torch[cosinembeddingloss](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html)

ä¸ºäº†ç”Ÿæˆé«˜è´¨é‡çš„ä¿¡æ¯ä¸°å¯Œçš„åµŒå…¥ï¼Œæ‚¨éœ€è¦å·²ç»åœ¨æ•°ç™¾ä¸‡æˆå¯¹ç¤ºä¾‹ä¸Šè®­ç»ƒè¿‡çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¹¶ä¸”æœ‰ä¸€äº›è®­ç»ƒæŠ€æœ¯(ä¾‹å¦‚ï¼Œä½¿ç”¨ç¡¬å¦å®šçš„å¯¹æ¯”å­¦ä¹ )å·²ç»è¢«åº”ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„åµŒå…¥ã€‚å¯¹äºä¸€èˆ¬çš„è¯­ä¹‰æœç´¢å’Œå¥å­è¡¨ç¤ºï¼Œåœ¨ [HuggingFace](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads) ä¸Šæœ‰å¤§é‡å…¬å¼€å¯ç”¨çš„é¢„è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ğŸ¤—ä»¥åŠä¸€äº›å•†ç”¨ API å¦‚ [cohere åµŒå…¥](https://docs.cohere.ai/docs/embeddings)å’Œ [OpenAI åµŒå…¥](https://beta.openai.com/docs/guides/embeddings)ç”¨äºç¼–ç æ–‡æœ¬ã€‚

# ç´¢å¼•å’Œæœç´¢

åœ¨å¯¹æˆ‘ä»¬çš„æ–‡æ¡£è¿›è¡Œç¼–ç (ç”Ÿæˆæ–‡æ¡£åµŒå…¥)ä¹‹åï¼Œæˆ‘ä»¬ç°åœ¨å¿…é¡»è€ƒè™‘ç´¢å¼•å‘é‡å’Œæœç´¢å¯†é›†ç´¢å¼•ã€‚

å‘é‡æœç´¢é€šå¸¸ä½¿ç”¨èšç±»ç®—æ³•(å¦‚æœ€è¿‘é‚»æœç´¢)æ¥å®Œæˆï¼Œç”±äºå„ç§åŸå› ï¼Œå®ƒå¯èƒ½æ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼Œå¹¶ä¸”å®æ–½èµ·æ¥å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå…¶ä¸­ä¸€äº›åŸå› æ˜¯:

(I .)ä¸€äº›ç¼–ç å™¨äº§ç”Ÿå…·æœ‰å¤§å°ºå¯¸çš„è¡¨ç¤ºå‘é‡ã€‚å¤§çš„åµŒå…¥å¯¼è‡´å¤§çš„åµŒå…¥è¡¨ï¼Œå½“æ‰§è¡Œå‘é‡æ“ä½œæ—¶å…·æœ‰é«˜çš„å­˜å‚¨å™¨æˆæœ¬ï¼Œå¹¶ä¸”å¯èƒ½å¢åŠ æœç´¢ç­‰å¾…æ—¶é—´ã€‚

(äºŒã€‚)ç”¨æ–°çš„å‘é‡æ›´æ–°å¯†é›†ç´¢å¼•å¯èƒ½è¦æ±‚å¾ˆé«˜ï¼Œå› ä¸ºæ‚¨å¯èƒ½éœ€è¦ä¸ºæ–°çš„å‘é‡æ›´æ–°ç´¢å¼•ç°‡ã€‚

ä¸€äº›å¼€æºåº“å·²ç»ä¸ºå¿«é€ŸçŸ¢é‡æœç´¢å»ºç«‹èµ·æ¥ï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œå¦‚ Meta çš„ [Faiss](https://github.com/facebookresearch/faiss) ï¼ŒSpotify çš„[angry](https://github.com/spotify/annoy)ï¼Œè°·æ­Œçš„ [ScaNN](https://github.com/google-research/google-research/tree/master/scann) ã€‚åœ¨[8.0](https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0)+ç‰ˆæœ¬ä¸­ï¼ŒElasticsearch å®£å¸ƒä»–ä»¬æµè¡Œçš„å¼€æºæœç´¢å¼•æ“ç°åœ¨æ”¯æŒæœ€è¿‘é‚»æœç´¢ã€‚

> **æ—æ³¨** : [å‚è§å…³äºä½¿ç”¨å¯†é›†å‘é‡å®ç°è¯­ä¹‰æœç´¢çš„ç¼ºç‚¹å’Œè§£å†³æ–¹æ¡ˆçš„è®¨è®º](https://news.ycombinator.com/item?id=29554986)ã€‚æ­¤å¤–ï¼Œ[å…³äºä¸åŒçš„è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•æœç´¢ç®—æ³•å’Œåº“ï¼Œå‚è§åŸºå‡†](http://ann-benchmarks.com/)ã€‚

# ä½¿ç”¨å¼¹æ€§æœç´¢çš„è¿‘ä¼¼æœç´¢

è®©æˆ‘ä»¬è¿›å…¥æœ‰è¶£çš„éƒ¨åˆ†ï¼

æˆ‘ä»¬å°†å¯¹ç”± 880 ä¸‡ç¯‡æ–‡ç« ç»„æˆçš„[MARCO å¥³å£«](https://microsoft.github.io/msmarco/Datasets.html)æ–‡ç« æ’åé›†åˆè¿›è¡Œç¼–ç å’Œç´¢å¼•ã€‚ç›®æ ‡æ˜¯æ ¹æ®æ®µè½ä¸ç»™å®šæŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹å®ƒä»¬è¿›è¡Œæ’åºã€‚ä¸‹è½½å¹¶è§£å‹ç¼©è¯¥é›†åˆã€‚

```
wget https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip
unzip msmarco.zip
```

æˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç åœ¨ä¸‹è½½åé¢„è§ˆæ•°æ®:

```
#inspect the data
head -1 msmarco/corpus.jsonl

#output
"""
{
  '_id': '0', 
  'title': '', 
  'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 
  'metadata': {}
}
""" 
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œç¼–ç ã€‚å¯¹äºæœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ‰˜ç®¡åœ¨ HuggingFace ä¸Šçš„[â€œå¥å­-å˜å½¢é‡‘åˆš/ms Marco-MiniLM-L6-cos-V5â€](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L6-cos-v5)æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ MS Marco passage ranking é›†åˆä¸Šè®­ç»ƒï¼Œä¸ºæ¯ä¸ªè¾“å…¥åºåˆ—äº§ç”Ÿ 384 é•¿åº¦çš„åµŒå…¥ã€‚æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªç¼–ç å™¨å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€æ®µæˆ–ä¸€æ‰¹æ–‡æœ¬ï¼Œå¹¶ä¸ºæ¯ä¸ªæ–‡æœ¬ç”ŸæˆåµŒå…¥ã€‚

è¯¥æ¨¡å‹ä¸ºè¾“å…¥å¥å­ä¸­çš„æ¯ä¸ªæ ‡è®°ç”Ÿæˆä¸åŒçš„åµŒå…¥é›†ã€‚æˆ‘ä»¬ä½¿ç”¨å¹³å‡æ± (ä¹Ÿç§°ä¸ºå¹³å‡æ± )æ¥èšé›†åµŒå…¥ã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸º[CLS]ä»¤ç‰Œç”Ÿæˆçš„åµŒå…¥å‘é‡ã€‚

> æ—æ³¨:[è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºåˆç”¨çš„åˆçº§è¯»æœ¬](https://blog.ml6.eu/the-art-of-pooling-embeddings-c56575114cf8)

```
class MSMarcoEncoder:
    def __init__(self, model_name: str, device : str='cpu'):
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.to(self.device)

    def encode(self, text:str, max_length: int):
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=max_length)
        inputs = inputs.to(self.device)
        with torch.no_grad():
            model_output = self.model(**inputs, return_dict=True)
        # Perform pooling
        embeddings = self.mean_pooling(model_output, inputs['attention_mask'])
        # Normalize embeddings
        embeddings = F.normalize(embeddings, p=2, dim=1)
        return embeddings.detach().cpu().numpy()

    def mean_pooling(self, model_output, attention_mask):
        token_embeddings = model_output[0] #First element of model_output contains all token embeddings
        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

if __name__ == "__main__":
    encoder = Encoder('sentence-transformers/msmarco-MiniLM-L6-cos-v5')
    embeddings = encoder.encode(batch_info['text'], 512) 
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†ç¼–ç å™¨ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ Elasticsearch ä¸­ç´¢å¼•æ•°æ®ï¼Œä¸ºäº†æœ‰æ•ˆåœ°åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªè¿­ä»£å™¨æ¥æ‰¹é‡å¾ªç¯æ•°æ®ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®å¹¶ç¡®ä¿ Elasticsearch æ­£åœ¨è¿è¡Œã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æŒ‰ç…§è¿™é‡Œçš„[æŒ‡ä»¤åœ¨æœ¬åœ°ä¸‹è½½å¹¶å¯åŠ¨ elasticsearch æœåŠ¡å™¨](https://www.elastic.co/downloads/elasticsearch)æˆ–è€…æŒ‰ç…§[è¿™ä¸ª](https://www.elastic.co/downloads/elasticsearch)å¯åŠ¨ä¸€ä¸ª elastic search å®¹å™¨ã€‚

å¯¹äºæœ¬åœ°è®¾ç½®ï¼Œåœ¨ä¸‹è½½ elasticsearch ä¹‹åï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¯åŠ¨ä¸€ä¸ªå…·æœ‰ä¸€ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤:

```
./elasticsearch-8.5.1/bin/elasticsearch
```

é»˜è®¤æƒ…å†µä¸‹ï¼ŒElasticSearch 8.0 åŠæ›´é«˜ç‰ˆæœ¬å¯ç”¨äº†å®‰å…¨æ€§ï¼Œå› æ­¤è¯·é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯æ‚¨æ˜¯å¦å¯ä»¥è¿æ¥åˆ°æ­£åœ¨è¿è¡Œçš„ ElasticSearch é›†ç¾¤:

```
curl --cacert config/certs/http_ca.crt -u elastic https://localhost:9200
```

ç°åœ¨æˆ‘ä»¬çš„ elasticsearch æœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªç´¢å¼•æ¥å­˜å‚¨æ•°æ®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ•°æ®é›†ä¸­çš„ä¸åŒå­—æ®µå®šä¹‰ä¸€ä¸ªæ˜ å°„ã€‚ç„¶è€Œï¼Œå¯¹äºæœ€è¿‘é‚»æœç´¢ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªç±»å‹ä¸º`dense_vector`çš„å­—æ®µï¼Œå®ƒå°†åŒ…å«æ¯ä¸ªæ–‡æ¡£çš„åµŒå…¥å†…å®¹ã€‚

```
from elasticsearch import Elasticsearch

es_client = Elasticsearch( "https://localhost:9200", 
                  http_auth=("username", "password"),
                  verify_certs=False)
config = {
    "mappings": {
        "properties": {
            "title": {"type": "text"},
            "text": {"type": "text"},
            "embeddings": {
                    "type": "dense_vector",
                    "dims": 384,
                    "index": false
                }
            }
    },
    "settings": {
        "number_of_shards": 2,
        "number_of_replicas": 1
    }
}

es_client.indices.create(
    index="msmarco-demo",
    settings=config["settings"],
    mappings=config["mappings"],
)

#check if the index has been created successfully
print(es.indices.exists(index=["msmarco-demo"]))
#True
```

ä¸‹é¢çš„ä»£ç ç‰‡æ®µä½¿ç”¨ elasticsearch çš„æ‰¹é‡ç´¢å¼• API æ¥æ‰¹é‡ç´¢å¼•æ–‡æ¡£ã€‚ä¸‹é¢çš„ä»£ç åœ¨`cpu`ä¸Šè¿è¡Œæ—¶é—´æ›´é•¿ï¼Œåœ¨`gpu or tpu`ä¸Šè¿è¡Œé€Ÿåº¦æ›´å¿«ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª[é›†åˆè¿­ä»£å™¨ç±»](https://gist.github.com/ToluClassics/bc4bbd8b7930ee35e237984c2c9998a1#file-knn_elasticsearch-py-L10-98)æ¥éå†æ•°æ®é›†ã€‚å¯¹äºæ¯ä¸€æ‰¹ï¼Œæˆ‘ä»¬ç”ŸæˆåµŒå…¥å¹¶ç´¢å¼•å®ƒä»¬ã€‚

```
collection_path = 'path/to/corpus.jsonl'
collection_iterator = JsonlCollectionIterator(collection_path, fields=['title','text'])
encoder = Encoder('sentence-transformers/msmarco-MiniLM-L6-cos-v5')
index_name = "msmarco-demo"

for batch_info in collection_iterator(batch_size=256, shard_id=0, shard_num=1):
    embeddings = encoder.encode(batch_info['text'], 512)
    batch_info["dense_vectors"] = embeddings

    actions = []
    for i in range(len(batch_info['id'])):
        action = {"index": {"_index": index_name, "_id": batch_info['id'][i]}}
        doc = {
                "title": batch_info['title'][i],
                "text": batch_info['text'][i],
                "embeddings": batch_info['dense_vectors'][i].tolist()
            }
        actions.append(action)
        actions.append(doc)

    es_client.bulk(index=index_name, operations=actions)

result = es_client.count(index=index_name)

#print the total number of documents in the index
print(result.body['count'])
#8841823

#output one document
print(es_client.get(index=["msmarco-demo"], id="0", request_timeout=60))

'''
{'_index': 'msmarco-demo', '_id': '0', '_version': 2, '_seq_no': 27, '_primary_term': 1, 'found': True, 
'_source': {'title': '', 
'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 
'embeddings': [-0.032267116010189056, 0.05750396102666855,...]}}
'''
```

ç°åœ¨ç´¢å¼•å·²ç»å®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥æœç´¢æˆ‘ä»¬çš„ç´¢å¼•ã€‚Elasticsearch æä¾›äº†ä¸€ä¸ª [python åŒ…è£…å™¨æ¥æ‰§è¡Œ KNN æœç´¢](https://elasticsearch-py.readthedocs.io/en/latest/api.html#elasticsearch.Elasticsearch.knn_search)ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨ä¸‹é¢ä»£ç ç‰‡æ®µä¸­å®šä¹‰çš„æœç´¢ä»£ç å‡½æ•°ä¸­ä½¿ç”¨çš„ã€‚ä¸ºäº†è¿›è¡Œæœç´¢ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å‚æ•°`k`å’Œ`query_vector`ä¸­çš„æŸ¥è¯¢åµŒå…¥æ¥å®šä¹‰æœç´¢é›†ç¾¤çš„æ•°é‡ã€‚

```
def search(query: str, es_client: Elasticsearch, model: str, index: str, top_k: int = 10):

    encoder = Encoder(model)
    query_vector = encoder.encode(query, max_length=64)
    query_dict = {
        "field": "embeddings",
        "query_vector": query_vector[0].tolist(),
        "k": 10,
        "num_candidates": top_k
    }
    res = es_client.knn_search(index=index, knn=query_dict, source=["title", "text", "id"])

    for hit in res["hits"]["hits"]:
        print(hit)
        print(f"Document ID: {hit['_id']}")
        print(f"Document Title: {hit['_source']['title']}")
        print(f"Document Text: {hit['_source']['text']}")
        print("=======================================================\n")

if __name__ == "__main__":

  search(query="What is the capital of France?", 
         es_client=es_client, 
         model="sentence-transformers/msmarco-MiniLM-L6-cos-v5", 
         index=index_name)
#output
"""
{'_index': 'msmarco-demo', '_id': '82390', '_score': 0.81541693, '_source': {'text': "In terms of total household wealth, France is the wealthiest nation in Europe and fourth in the world. It also possesses the world's second-largest exclusive economic zone (EEZ), covering 11,035,000 square kilometres (4,261,000 sq mi).", 'title': ''}}
Document ID: 82390
Document Title: 
Document Text: In terms of total household wealth, France is the wealthiest nation in Europe and fourth in the world. It also possesses the world's second-largest exclusive economic zone (EEZ), covering 11,035,000 square kilometres (4,261,000 sq mi).
=====================================================================

{'_index': 'msmarco-demo', '_id': '162291', '_score': 0.80739325, '_source': {'text': 'Paris in France lies on the Seine River. The docking location is Port de Grenelle/Quai de Grenelle. As one of the largest cities in Europe, finding a property that suit your budget is not a problem. Choose between low cost guest rooms to luxury 4 and 5 star hotels and apartments to rent.', 'title': ''}}
Document ID: 162291
Document Title: 
Document Text: Paris in France lies on the Seine River. The docking location is Port de Grenelle/Quai de Grenelle. As one of the largest cities in Europe, finding a property that suit your budget is not a problem. Choose between low cost guest rooms to luxury 4 and 5 star hotels and apartments to rent.
=====================================================================
"""
```

å‘é‡æœç´¢ç°åœ¨æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ—¶é«¦é¢†åŸŸï¼Œæœ‰å¾ˆå¤šå…¶ä»–å¾ˆæ£’çš„åº“æä¾›å‘é‡æœç´¢åŠŸèƒ½ï¼Œå¦‚[æ¾æœ](https://www.pinecone.io/)ã€[çºªå¨œ AI](https://jina.ai/) ã€ [Weaviate](https://weaviate.io/) ã€ [Qdrant](https://qdrant.tech/) ç­‰ã€‚

ç§å•Šã€‚ç”¨ Github Copilot å¼€å‘è¿™ä¸ªå¾ˆæœ‰è¶£ã€‚è¦ç¦»çº¿ç´¢å¼•å’Œæœç´¢ï¼Œè¯·ä¸è¦çŠ¹è±«ï¼Œæ¥çœ‹çœ‹æˆ‘ä»¬ä»¤äººæ•¬ç•çš„å›¾ä¹¦é¦† [Pyserini](https://github.com/castorini/pyserini) ã€‚Pyserini ä¸»è¦è®¾è®¡ç”¨äºåœ¨å¤šçº§æ’åæ¶æ„ä¸­æä¾›æœ‰æ•ˆçš„ã€å¯é‡å¤çš„ã€æ˜“äºä½¿ç”¨çš„ç¬¬ä¸€çº§æ£€ç´¢ã€‚

è¿™ä¸ªæ•™ç¨‹çš„å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://gist.github.com/ToluClassics/bc4bbd8b7930ee35e237984c2c9998a1)æ‰¾åˆ°ã€‚

# å‚è€ƒ

1.  [https://towards data science . com/how-to-index-elastic search-documents-with-the-bulk-API-in-python-b5 bb 01 ed 3824](https://towardsdatascience.com/how-to-index-elasticsearch-documents-with-the-bulk-api-in-python-b5bb01ed3824)
2.  [https://www.elastic.co/](https://www.elastic.co/)